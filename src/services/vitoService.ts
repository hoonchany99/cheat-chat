// ë¦¬í„´ì œë¡œ VITO STT API ì„œë¹„ìŠ¤ - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ + GPT í™”ìë¶„ë¥˜
// ë…¹ìŒ ì¤‘ VITO ì‹¤ì‹œê°„ ì „ì‚¬ â†’ ë…¹ìŒ ì¢…ë£Œ í›„ GPT í™”ì ë¶„ë¥˜

const VITO_CLIENT_ID = import.meta.env.VITE_VITO_CLIENT_ID || '';
const VITO_CLIENT_SECRET = import.meta.env.VITE_VITO_CLIENT_SECRET || '';
const OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY || '';

// í™”ìë³„ ì„¸ê·¸ë¨¼íŠ¸ ì¸í„°í˜ì´ìŠ¤
export interface SpeakerSegment {
  speaker: 'doctor' | 'patient' | 'pending';
  text: string;
  startTime?: number;
  endTime?: number;
}

// í† í° ìºì‹œ
let cachedToken: string | null = null;
let tokenExpiry: number = 0;

// ì§„ë£Œê³¼ë³„ ì˜ë£Œ í‚¤ì›Œë“œ (í‚¤ì›Œë“œ ë¶€ìŠ¤íŒ…ìš©) - í•œê¸€ë§Œ í—ˆìš©
const MEDICAL_KEYWORDS: Record<string, string[]> = {
  general: [
    'í˜ˆì••', 'ë§¥ë°•', 'ì²´ì˜¨', 'í˜¸í¡', 'ì‚°ì†Œí¬í™”ë„',
    'ì²˜ë°©', 'íˆ¬ì•½', 'ì§„ë‹¨', 'ì¦ìƒ', 'ê²½ê³¼',
    'ê²€ì‚¬', 'í˜ˆì•¡ê²€ì‚¬', 'ì—‘ìŠ¤ë ˆì´', 'ì‹œí‹°', 'ì— ì•Œì•„ì´',
    'í™˜ì', 'ì˜ì‚¬', 'ì„ ìƒë‹˜', 'ì›ì¥ë‹˜',
  ],
  internal: [
    'ìœ„ì—¼', 'ì—­ë¥˜ì„±', 'ì†Œí™”ë¶ˆëŸ‰', 'ë³€ë¹„', 'ì„¤ì‚¬',
    'ê³ í˜ˆì••', 'ë‹¹ë‡¨', 'ê³ ì§€í˜ˆì¦', 'ê°„ìˆ˜ì¹˜', 'ì‹ ì¥',
    'ë‚´ì‹œê²½', 'ì´ˆìŒíŒŒ', 'ì‹¬ì „ë„', 'íê¸°ëŠ¥',
  ],
  dermatology: [
    'ì—¬ë“œë¦„', 'ìŠµì§„', 'ì•„í† í”¼', 'ê±´ì„ ', 'ë‘ë“œëŸ¬ê¸°',
    'ë°œì§„', 'ê°€ë ¤ì›€', 'ìƒ‰ì†Œì¹¨ì°©', 'í‰í„°', 'ë ˆì´ì €',
    'ì—°ê³ ', 'ìŠ¤í…Œë¡œì´ë“œ', 'í•­íˆìŠ¤íƒ€ë¯¼',
  ],
  orthopedics: [
    'ê³¨ì ˆ', 'ì—¼ì¢Œ', 'íƒˆêµ¬', 'ê´€ì ˆì—¼', 'ë””ìŠ¤í¬',
    'ì²™ì¶”', 'ë¬´ë¦', 'ì–´ê¹¨', 'í—ˆë¦¬', 'ëª©',
    'ë¬¼ë¦¬ì¹˜ë£Œ', 'ì¬í™œ', 'ê¹ìŠ¤', 'ë³´ì¡°ê¸°',
  ],
  psychiatry: [
    'ìš°ìš¸ì¦', 'ë¶ˆì•ˆ', 'ê³µí™©', 'ë¶ˆë©´ì¦', 'ìŠ¤íŠ¸ë ˆìŠ¤',
    'ì¡°í˜„ë³‘', 'ì–‘ê·¹ì„±', 'ê°•ë°•', 'ì£¼ì˜ë ¥ê²°í•', 'ì¹˜ë§¤',
    'ìƒë‹´', 'ì•½ë¬¼ì¹˜ë£Œ', 'ì¸ì§€í–‰ë™ì¹˜ë£Œ',
  ],
  pediatrics: [
    'ë°œì—´', 'ê°ê¸°', 'ê¸°ì¹¨', 'ì½§ë¬¼', 'ì¤‘ì´ì—¼',
    'ì˜ˆë°©ì ‘ì¢…', 'ì„±ì¥', 'ë°œë‹¬', 'ëª¨ìœ ', 'ë¶„ìœ ',
    'ì•„í† í”¼', 'ì•Œë ˆë¥´ê¸°', 'ì²œì‹',
  ],
  dentistry: [
    'ì¶©ì¹˜', 'ì¹˜ì•„', 'ì‡ëª¸', 'ì¹˜ì£¼ì—¼', 'ì¹˜ì€ì—¼',
    'ì‹ ê²½ì¹˜ë£Œ', 'ë°œì¹˜', 'ì„í”Œë€íŠ¸', 'í¬ë¼ìš´', 'ë¸Œë¦¿ì§€',
    'ìŠ¤ì¼€ì¼ë§', 'ì‚¬ë‘ë‹ˆ', 'êµì •', 'ì¹˜ì„', 'ì¹˜íƒœ',
    'ë²•ë‘ì§ˆ', 'ìƒì•„ì§ˆ', 'ì¹˜ìˆ˜', 'ì¹˜ê·¼', 'ì¹˜ì¡°ê³¨',
    'ë¶ˆì†Œ', 'ë ˆì§„', 'ì•„ë§ê°', 'ì„¸ë¼ë¯¹',
  ],
  custom: [],
};

// í™˜ê° í•„í„° íŒ¨í„´
const HALLUCINATION_PATTERNS = [
  /êµ¬ë….*ì¢‹ì•„ìš”/gi,
  /ì¢‹ì•„ìš”.*êµ¬ë…/gi,
  /ì‹œì²­.*ê°ì‚¬/gi,
  /Thanks.*watching/gi,
  /subscribe/gi,
  /ìƒˆí•´\s*ë³µ\s*ë§ì´/gi,
  /ë¸”ë£¨ë ˆë“œ|ì˜ìƒ\s*íš¨ê³¼/gi,
];

function filterHallucinations(text: string): string {
  let filtered = text;
  for (const pattern of HALLUCINATION_PATTERNS) {
    filtered = filtered.replace(pattern, '').trim();
  }
  return filtered.replace(/\s+/g, ' ').trim();
}

// GPT ê¸°ë°˜ í™”ì ë¶„ë¥˜ + ë°œí™” ì¬ë¶„ë¦¬ í•¨ìˆ˜
async function classifySpeakersWithGPT(
  fullText: string
): Promise<SpeakerSegment[]> {
  if (!OPENAI_API_KEY) {
    console.warn('âš ï¸ OpenAI API í‚¤ ì—†ìŒ, í™”ìë¶„ë¥˜ ê±´ë„ˆëœ€');
    return [{ speaker: 'pending', text: fullText }];
  }

  if (!fullText.trim()) {
    console.warn('âš ï¸ ì „ì‚¬ëœ í…ìŠ¤íŠ¸ ì—†ìŒ');
    return [];
  }

  console.log('ğŸ¤– GPT í™”ì ë¶„ë¥˜ ì‹œì‘...');
  console.log('ğŸ“ ì…ë ¥ í…ìŠ¤íŠ¸:', fullText.substring(0, 200) + '...');

  const prompt = `í•œêµ­ì–´ ì˜ë£Œ ìƒë‹´ ëŒ€í™”ë¥¼ ì˜ì‚¬(D)ì™€ í™˜ì(P)ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

## í•µì‹¬ ê·œì¹™

**ì˜ì‚¬(D)ì˜ íŠ¹ì§•:**
- ì§ˆë¬¸ì„ í•¨: "~ì„¸ìš”?", "~ë‚˜ìš”?", "~ì‹œì£ ?", "ìˆìœ¼ì„¸ìš”?"
- ì„ íƒì§€ ì œì‹œ: "ì•„ë‹ˆë©´~", "~ê±°ë‚˜~", "ë˜ëŠ”~"
- ì§€ì‹œ/ì•ˆë‚´: "~í•´ë³¼ê²Œìš”", "~ë“œë¦´ê²Œìš”"
- ì˜ë£Œ ìš©ì–´ ì„¤ëª…

**í™˜ì(P)ì˜ íŠ¹ì§•:**
- ì¦ìƒ ì„¤ëª…: "~ì•„íŒŒìš”", "~ë–¨ë ¤ìš”", "~ê²ƒ ê°™ìŠµë‹ˆë‹¤", "~ê²ƒ ê°™ì•„ìš”"
- ì§ˆë¬¸ì— ëŒ€ë‹µ: "ë„¤", "ì˜ˆ", "ì•„ë‹ˆìš”", êµ¬ì²´ì  ì •ë³´ ì œê³µ
- ê¸°ê°„/ì •ë„ ë‹µë³€: "3ê°œì›” ì „ë¶€í„°", "ë§ì´", "ì¡°ê¸ˆ"

## ì˜ˆì‹œ

ì…ë ¥: "ì´ë¦„ì€ í™ê¸¸ë™ì´ê³  123456ë²ˆì…ë‹ˆë‹¤. ì–´ë–»ê²Œ ì˜¤ì…¨ì–´ìš”?"
â†’ P: "ì´ë¦„ì€ í™ê¸¸ë™ì´ê³  123456ë²ˆì…ë‹ˆë‹¤."
â†’ D: "ì–´ë–»ê²Œ ì˜¤ì…¨ì–´ìš”?"

## ì…ë ¥ í…ìŠ¤íŠ¸
${fullText}

## ì¶œë ¥
ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´:
[{"speaker": "D", "text": "..."}, {"speaker": "P", "text": "..."}, ...]`;

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0,
        max_tokens: 4000,
      }),
    });

    if (!response.ok) {
      throw new Error(`GPT API ì˜¤ë¥˜: ${response.status}`);
    }

    const data = await response.json();
    const content = data.choices[0]?.message?.content?.trim() || '';
    
    console.log('ğŸ¤– GPT ì‘ë‹µ:', content.substring(0, 300) + '...');

    // JSON ë°°ì—´ íŒŒì‹±
    const jsonMatch = content.match(/\[[\s\S]*\]/);
    if (!jsonMatch) {
      throw new Error('GPT ì‘ë‹µì—ì„œ JSON ë°°ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ');
    }

    const parsed: Array<{ speaker: string; text: string }> = JSON.parse(jsonMatch[0]);
    
    const result: SpeakerSegment[] = parsed.map((item) => ({
      speaker: item.speaker === 'D' ? 'doctor' : 'patient',
      text: item.text,
    }));

    // ê²°ê³¼ ë¡œê¹…
    const doctorCount = result.filter(s => s.speaker === 'doctor').length;
    const patientCount = result.filter(s => s.speaker === 'patient').length;
    console.log(`âœ… GPT í™”ì ë¶„ë¥˜ ì™„ë£Œ: ğŸ‘¨â€âš•ï¸ ì˜ì‚¬ ${doctorCount}ê°œ, ğŸ™‹ í™˜ì ${patientCount}ê°œ`);

    return result;
  } catch (error) {
    console.error('âŒ GPT í™”ì ë¶„ë¥˜ ì˜¤ë¥˜:', error);
    return [{ speaker: 'pending', text: fullText }];
  }
}

// JWT í† í° ë°œê¸‰
async function getAccessToken(): Promise<string> {
  if (cachedToken && Date.now() < tokenExpiry - 60000) {
    return cachedToken;
  }

  if (!VITO_CLIENT_ID || !VITO_CLIENT_SECRET) {
    throw new Error('VITO API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
  }

  console.log('ğŸ”‘ VITO í† í° ë°œê¸‰ ìš”ì²­...');

  const response = await fetch('/api/vito/v1/authenticate', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/x-www-form-urlencoded',
    },
    body: `client_id=${encodeURIComponent(VITO_CLIENT_ID)}&client_secret=${encodeURIComponent(VITO_CLIENT_SECRET)}`,
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`VITO ì¸ì¦ ì˜¤ë¥˜: ${response.status} - ${errorText}`);
  }

  const data = await response.json();
  cachedToken = data.access_token;
  tokenExpiry = Date.now() + (data.expire_at ? data.expire_at * 1000 : 3600000);
  
  console.log('âœ… VITO í† í° ë°œê¸‰ ì™„ë£Œ');
  return cachedToken!;
}

// VITO ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ í´ë˜ìŠ¤
export class VitoRealtimeTranscriber {
  private ws: WebSocket | null = null;
  private onRealtimeText: (text: string) => void;
  private onFullUpdate: (segments: SpeakerSegment[]) => void;
  private department: string;
  private accumulatedText: string = ''; // ëˆ„ì  í…ìŠ¤íŠ¸ (ìµœì¢… ê²°ê³¼ë§Œ)
  private currentInterim: string = ''; // í˜„ì¬ ì„ì‹œ ê²°ê³¼
  private isConnected: boolean = false;
  private audioContext: AudioContext | null = null;
  private recordingDuration: number = 0;
  
  constructor(
    onRealtimeText: (text: string) => void,
    onFullUpdate?: (segments: SpeakerSegment[]) => void,
    department: string = 'general'
  ) {
    this.onRealtimeText = onRealtimeText;
    this.onFullUpdate = onFullUpdate || (() => {});
    this.department = department;
    console.log('ğŸ¥ VitoRealtimeTranscriber ìƒì„±, ì§„ë£Œê³¼:', department);
  }

  // WebSocket ì—°ê²° ì‹œì‘
  async connect(): Promise<void> {
    try {
      const token = await getAccessToken();
      
      // ì˜ë£Œ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
      const keywords = [
        ...MEDICAL_KEYWORDS.general,
        ...(MEDICAL_KEYWORDS[this.department] || []),
      ].slice(0, 100);

      // WebSocket ì—°ê²° (VITO ìŠ¤íŠ¸ë¦¬ë° API)
      const config = {
        sample_rate: '16000',
        encoding: 'LINEAR16',
        use_itn: 'true',
        use_disfluency_filter: 'true',
        use_profanity_filter: 'false',
        keywords: keywords.join(','),
      };

      const queryString = new URLSearchParams(config).toString();
      const wsUrl = `wss://openapi.vito.ai/v1/transcribe:streaming?${queryString}`;
      
      console.log('ğŸ”Œ VITO WebSocket ì—°ê²° ì‹œë„...');
      
      this.ws = new WebSocket(wsUrl, ['bearer', token]);
      
      this.ws.onopen = () => {
        console.log('âœ… VITO WebSocket ì—°ê²°ë¨');
        this.isConnected = true;
      };

      this.ws.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          
          if (data.final) {
            // ìµœì¢… ê²°ê³¼
            const text = filterHallucinations(data.alternatives?.[0]?.text || '');
            if (text) {
              this.accumulatedText += text + ' ';
              this.currentInterim = '';
              console.log('ğŸ“ ìµœì¢…:', text);
            }
          } else {
            // ì„ì‹œ ê²°ê³¼
            this.currentInterim = data.alternatives?.[0]?.text || '';
          }
          
          // UI ì—…ë°ì´íŠ¸ (ëˆ„ì  + í˜„ì¬ ì„ì‹œ)
          const displayText = (this.accumulatedText + this.currentInterim).trim();
          this.onRealtimeText(displayText);
          
        } catch (e) {
          console.error('ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', e);
        }
      };

      this.ws.onerror = (error) => {
        console.error('âŒ VITO WebSocket ì˜¤ë¥˜:', error);
      };

      this.ws.onclose = (event) => {
        console.log('ğŸ”Œ VITO WebSocket ë‹«í˜:', event.code, event.reason);
        this.isConnected = false;
      };

      // ì—°ê²° ëŒ€ê¸°
      await new Promise<void>((resolve, reject) => {
        const timeout = setTimeout(() => {
          reject(new Error('WebSocket ì—°ê²° íƒ€ì„ì•„ì›ƒ'));
        }, 10000);

        this.ws!.onopen = () => {
          clearTimeout(timeout);
          this.isConnected = true;
          console.log('âœ… VITO WebSocket ì—°ê²°ë¨');
          resolve();
        };

        this.ws!.onerror = () => {
          clearTimeout(timeout);
          reject(new Error('WebSocket ì—°ê²° ì‹¤íŒ¨'));
        };
      });

    } catch (error) {
      console.error('âŒ VITO ì—°ê²° ì˜¤ë¥˜:', error);
      throw error;
    }
  }

  // ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡ (webm â†’ PCM ë³€í™˜ í•„ìš”)
  async addChunk(chunk: Blob, _isSilent: boolean = false, elapsedTime?: number): Promise<void> {
    if (elapsedTime !== undefined) {
      this.recordingDuration = elapsedTime;
    }

    if (!this.isConnected || !this.ws || this.ws.readyState !== WebSocket.OPEN) {
      return;
    }

    try {
      // webm blobì„ ArrayBufferë¡œ ë³€í™˜
      const arrayBuffer = await chunk.arrayBuffer();
      
      // PCMìœ¼ë¡œ ë³€í™˜ (AudioContext ì‚¬ìš©)
      if (!this.audioContext) {
        this.audioContext = new AudioContext({ sampleRate: 16000 });
      }
      
      try {
        const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer.slice(0));
        const pcmData = this.convertToPCM16(audioBuffer);
        
        if (this.ws.readyState === WebSocket.OPEN) {
          this.ws.send(pcmData);
        }
      } catch {
        // ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ (ì¼ë¶€ ì²­í¬ëŠ” ë‹¨ë…ìœ¼ë¡œ ë””ì½”ë”© ë¶ˆê°€)
      }
    } catch (error) {
      // ì¡°ìš©íˆ ì‹¤íŒ¨ (ì—°ì† ìŠ¤íŠ¸ë¦¼ì—ì„œ ì¼ë¶€ ì²­í¬ ì‹¤íŒ¨ëŠ” ì •ìƒ)
    }
  }

  // AudioBufferë¥¼ 16-bit PCMìœ¼ë¡œ ë³€í™˜
  private convertToPCM16(audioBuffer: AudioBuffer): ArrayBuffer {
    const channelData = audioBuffer.getChannelData(0);
    const pcmData = new Int16Array(channelData.length);
    
    for (let i = 0; i < channelData.length; i++) {
      const s = Math.max(-1, Math.min(1, channelData[i]));
      pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    
    return pcmData.buffer;
  }

  // ë…¹ìŒ ì¢…ë£Œ ë° í™”ì ë¶„ë¥˜
  async flush(): Promise<SpeakerSegment[]> {
    console.log('ğŸ”š flush() í˜¸ì¶œ - ë…¹ìŒ ì¢…ë£Œ ë° í™”ì ë¶„ë¥˜');
    
    // WebSocket ë‹«ê¸°
    if (this.ws) {
      if (this.ws.readyState === WebSocket.OPEN) {
        // EOS ì‹ í˜¸ ì „ì†¡
        this.ws.send('EOS');
      }
      
      // ì ì‹œ ëŒ€ê¸° í›„ ë‹«ê¸°
      await new Promise(resolve => setTimeout(resolve, 500));
      this.ws.close();
      this.ws = null;
    }

    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }

    // ìµœì¢… í…ìŠ¤íŠ¸ í™•ì¸
    const finalText = this.accumulatedText.trim();
    console.log('ğŸ“ ìµœì¢… ì „ì‚¬ í…ìŠ¤íŠ¸:', finalText.substring(0, 200) + '...');
    console.log(`ğŸ“Š ì´ ê¸¸ì´: ${finalText.length}ì, ë…¹ìŒ ì‹œê°„: ${this.recordingDuration.toFixed(1)}ì´ˆ`);

    if (!finalText) {
      console.log('âš ï¸ ì „ì‚¬ëœ í…ìŠ¤íŠ¸ ì—†ìŒ');
      return [];
    }

    // GPTë¡œ í™”ì ë¶„ë¥˜
    const segments = await classifySpeakersWithGPT(finalText);
    
    this.onFullUpdate(segments);
    
    return segments;
  }

  // ì „ì²´ ì „ì‚¬ í…ìŠ¤íŠ¸ ë°˜í™˜
  getFullText(): string {
    return this.accumulatedText.trim();
  }

  // ì—°ê²° ìƒíƒœ í™•ì¸
  isActive(): boolean {
    return this.isConnected;
  }

  // ì´ˆê¸°í™”
  reset(): void {
    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
    this.accumulatedText = '';
    this.currentInterim = '';
    this.isConnected = false;
    this.recordingDuration = 0;
    console.log('ğŸ”„ VitoRealtimeTranscriber ë¦¬ì…‹');
  }
}

// ê¸°ë³¸ export
export default {
  VitoRealtimeTranscriber,
};

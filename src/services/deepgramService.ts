// Deepgram ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° STT + GPT í™”ìë¶„ë¥˜
// ë…¹ìŒ ì¤‘: Deepgram ì‹¤ì‹œê°„ ì „ì‚¬ + GPT-4o-mini ë°°ì¹˜ í™”ìë¶„ë¥˜
// ë…¹ìŒ ì¢…ë£Œ: GPT-4o ì •í™•í•œ í™”ìë¶„ë¥˜

const DEEPGRAM_API_KEY = import.meta.env.VITE_DEEPGRAM_API_KEY || '';
const OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY || '';

// í™”ìë³„ ì„¸ê·¸ë¨¼íŠ¸ ì¸í„°í˜ì´ìŠ¤
export interface SpeakerSegment {
  speaker: 'doctor' | 'patient' | 'pending';
  text: string;
  startTime?: number;
  endTime?: number;
}

// í™˜ê° í•„í„° íŒ¨í„´
const HALLUCINATION_PATTERNS = [
  /êµ¬ë….*ì¢‹ì•„ìš”/gi,
  /ì¢‹ì•„ìš”.*êµ¬ë…/gi,
  /ì‹œì²­.*ê°ì‚¬/gi,
  /Thanks.*watching/gi,
  /subscribe/gi,
];

function filterHallucinations(text: string): string {
  let filtered = text;
  for (const pattern of HALLUCINATION_PATTERNS) {
    filtered = filtered.replace(pattern, '').trim();
  }
  return filtered.replace(/\s+/g, ' ').trim();
}

// GPT-4o ì „ì²´ ë°œí™” ì¬êµ¬ì„± + í™”ì ë¶„ë¥˜
async function classifyUtterancesWithGPT(utterances: string[]): Promise<SpeakerSegment[]> {
  if (!OPENAI_API_KEY || utterances.length === 0) {
    console.warn('âš ï¸ OpenAI API í‚¤ ì—†ìŒ ë˜ëŠ” ë°œí™” ì—†ìŒ');
    return utterances.map(text => ({ speaker: 'pending', text }));
  }

  console.log(`ğŸ¤– GPT-4o ì „ì²´ ${utterances.length}ê°œ ë°œí™” ë¶„ë¥˜ ì‹œì‘...`);

  // ë°œí™”ë¥¼ ë²ˆí˜¸ë¡œ êµ¬ë¶„í•´ì„œ ì „ì†¡
  const numberedUtterances = utterances.map((u, i) => `[${i + 1}] ${u}`).join('\n');

  const prompt = `ì˜ë£Œ ìƒë‹´ ëŒ€í™”ì…ë‹ˆë‹¤. ì „ì²´ ë°œí™”ë¥¼ ì¬êµ¬ì„±í•˜ê³  í™”ì(D=ì˜ì‚¬, P=í™˜ì)ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”.

## í™”ì êµ¬ë¶„ ê¸°ì¤€
- ì˜ì‚¬(D): ì§ˆë¬¸("~ì„¸ìš”?"), ì„¤ëª…, ì§€ì‹œ, ì•ˆë‚´, ì§„ë£Œ ê´€ë ¨ ì–¸ê¸‰
- í™˜ì(P): ì¦ìƒ ì„¤ëª…, ëŒ€ë‹µ("ë„¤", "ì•„ë‹ˆìš”"), ê°ì‚¬ ì¸ì‚¬, ê°œì¸ì •ë³´

## ì¬êµ¬ì„± ê·œì¹™ (ì¤‘ìš”!)
1. **ëŠê¸´ ë¬¸ì¥ í•©ì¹˜ê¸°**: ì—°ì†ëœ ë°œí™”ê°€ í•˜ë‚˜ì˜ ë¬¸ì¥ì¸ë° ì¤‘ê°„ì— ëŠê¸´ ê²½ìš° í•©ì³ì„œ ì¶œë ¥
   - ì˜ˆ: "[1] ì•ˆë…•í•˜ì„¸ìš” ê¹€ì„œí˜„ë‹˜ ì˜¤ëŠ˜ ì–´ë–¤" + "[2] ë¶ˆí¸í•¨ìœ¼ë¡œ ì˜¤ì…¨ë‚˜ìš”?"
   â†’ {"speaker": "D", "text": "ì•ˆë…•í•˜ì„¸ìš” ê¹€ì„œí˜„ë‹˜ ì˜¤ëŠ˜ ì–´ë–¤ ë¶ˆí¸í•¨ìœ¼ë¡œ ì˜¤ì…¨ë‚˜ìš”?"}

2. **ì„ì¸ í™”ì ë¶„ë¦¬**: í•œ ë°œí™” ì•ˆì— ë‘ í™”ìì˜ ë§ì´ ì„ì—¬ ìˆìœ¼ë©´ ë¶„ë¦¬
   - ì˜ˆ: "[1] ê°ì‚¬í•©ë‹ˆë‹¤ ì›ì¥ë‹˜ ë¶ˆí¸í•˜ì‹œë©´ ë‹¤ì‹œ ì˜¤ì„¸ìš”"
   â†’ {"speaker": "P", "text": "ê°ì‚¬í•©ë‹ˆë‹¤ ì›ì¥ë‹˜"}, {"speaker": "D", "text": "ë¶ˆí¸í•˜ì‹œë©´ ë‹¤ì‹œ ì˜¤ì„¸ìš”"}

3. **ê°™ì€ í™”ì ì—°ì† ë°œí™”**: ê°™ì€ í™”ìì˜ ì—°ì†ëœ ì§§ì€ ë°œí™”ëŠ” í•©ì³ë„ ë¨
   - ì˜ˆ: "[1] ë„¤ ë§ì•„ìš”" + "[2] í‰ì†Œì—ëŠ” ê´œì°®ì€ë°"
   â†’ {"speaker": "P", "text": "ë„¤ ë§ì•„ìš”, í‰ì†Œì—ëŠ” ê´œì°®ì€ë°"}

## ë°œí™” ëª©ë¡
${numberedUtterances}

## ì¶œë ¥ í˜•ì‹ (JSON ë°°ì—´ë§Œ)
[{"speaker": "D", "text": "ì¬êµ¬ì„±ëœ ì™„ì „í•œ ë¬¸ì¥"}, ...]

- ëª¨ë“  ë‚´ìš©ì„ ë¹ ì§ì—†ì´ í¬í•¨í•˜ì„¸ìš”
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”`;

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0,
        max_tokens: 2000,
      }),
    });

    if (!response.ok) {
      throw new Error(`GPT API ì˜¤ë¥˜: ${response.status}`);
    }

    const data = await response.json();
    const content = data.choices[0]?.message?.content?.trim() || '';
    
    const jsonMatch = content.match(/\[[\s\S]*\]/);
    if (!jsonMatch) {
      throw new Error('GPT ì‘ë‹µì—ì„œ JSON ë°°ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ');
    }

    const parsed: Array<{ speaker: string; text: string }> = JSON.parse(jsonMatch[0]);
    
    // ì¬êµ¬ì„±ëœ ë°œí™” ì²˜ë¦¬
    const result: SpeakerSegment[] = parsed
      .filter(item => item.text && item.text.trim())
      .map((item) => ({
        speaker: item.speaker === 'D' ? 'doctor' : 'patient',
        text: item.text.trim()
      }));

    console.log(`âœ… GPT-4o í™”ì ë¶„ë¥˜ ì™„ë£Œ: ğŸ‘¨â€âš•ï¸ ì˜ì‚¬ ${result.filter(s => s.speaker === 'doctor').length}ê°œ, ğŸ™‹ í™˜ì ${result.filter(s => s.speaker === 'patient').length}ê°œ`);

    return result;
  } catch (error) {
    console.error('âŒ GPT-4o í™”ì ë¶„ë¥˜ ì˜¤ë¥˜:', error);
    return utterances.map(text => ({ speaker: 'pending', text }));
  }
}

// Deepgram ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ í´ë˜ìŠ¤
export class DeepgramRealtimeTranscriber {
  private ws: WebSocket | null = null;
  private onRealtimeSegment: (segment: SpeakerSegment) => void;
  private onSegmentsUpdate: (segments: SpeakerSegment[]) => void;
  private onFullUpdate: (segments: SpeakerSegment[]) => void;
  private isConnected: boolean = false;
  private utterances: string[] = []; // ë°œí™” ë°°ì—´ë¡œ ê´€ë¦¬
  private classifiedSegments: SpeakerSegment[] = []; // ë¶„ë¥˜ ì™„ë£Œëœ ì„¸ê·¸ë¨¼íŠ¸
  private classifiedUtteranceCount: number = 0; // ë¶„ë¥˜ ì™„ë£Œëœ ë°œí™” ê°œìˆ˜
  private isClassifying: boolean = false;
  private classifyTimer: ReturnType<typeof setTimeout> | null = null;
  private readonly WINDOW_SIZE = 5; // í•œ ë²ˆì— ë¶„ë¥˜í•  ë°œí™” ê°œìˆ˜
  
  constructor(
    onRealtimeSegment: (segment: SpeakerSegment) => void,
    onFullUpdate?: (segments: SpeakerSegment[]) => void,
    _department: string = 'general'
  ) {
    this.onRealtimeSegment = onRealtimeSegment;
    this.onSegmentsUpdate = () => {};
    this.onFullUpdate = onFullUpdate || (() => {});
    console.log(`ğŸ™ï¸ DeepgramRealtimeTranscriber ìƒì„± (ìµœê·¼ ${this.WINDOW_SIZE}ê°œ ë°œí™” í™”ìë¶„ë¥˜)`);
  }

  // ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ ì—…ë°ì´íŠ¸ ì½œë°± ì„¤ì •
  setOnSegmentsUpdate(callback: (segments: SpeakerSegment[]) => void) {
    this.onSegmentsUpdate = callback;
  }

  // WebSocket ì—°ê²° ì‹œì‘
  async connect(): Promise<void> {
    if (!DEEPGRAM_API_KEY) {
      throw new Error('Deepgram API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. VITE_DEEPGRAM_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.');
    }

    console.log('ğŸ”Œ Deepgram WebSocket ì—°ê²° ì‹œë„...');

    const params = new URLSearchParams({
      model: 'nova-2',
      language: 'ko',
      punctuate: 'true',
      smart_format: 'true',        // ìŠ¤ë§ˆíŠ¸ í¬ë§· (ìˆ«ì, ë‚ ì§œ ë“±)
      interim_results: 'true',
      utterance_end_ms: '1500',    // ë°œí™” ì¢…ë£Œ ê°ì§€ (1.5ì´ˆ ì¹¨ë¬µ)
      endpointing: '800',          // ë¬¸ì¥ ëŠê¹€ ë°©ì§€ (800msë¡œ ëŠ˜ë¦¼)
      vad_events: 'true',
    });

    const wsUrl = `wss://api.deepgram.com/v1/listen?${params.toString()}`;
    
    this.ws = new WebSocket(wsUrl, ['token', DEEPGRAM_API_KEY]);

    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error('WebSocket ì—°ê²° íƒ€ì„ì•„ì›ƒ'));
      }, 10000);

      this.ws!.onopen = () => {
        clearTimeout(timeout);
        this.isConnected = true;
        console.log('âœ… Deepgram WebSocket ì—°ê²°ë¨');
        resolve();
      };

      this.ws!.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          
          if (data.type === 'Results') {
            const transcript = data.channel?.alternatives?.[0]?.transcript || '';
            const isFinal = data.is_final;

            // ğŸ” RAW DATA ë¡œê¹… (finalë§Œ)
            if (transcript && isFinal) {
              console.log(`ğŸ¤ [Deepgram RAW] "${transcript}"`);
              
              const filteredText = filterHallucinations(transcript);
              if (filteredText) {
                console.log(`âœ… [í•„í„° í›„] "${filteredText}"`);
                this.handleNewUtterance(filteredText);
              } else {
                console.log(`âŒ [í•„í„°ë¨ - hallucination]`);
              }
            }
          }
        } catch (e) {
          console.error('ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', e);
        }
      };

      this.ws!.onerror = (error) => {
        clearTimeout(timeout);
        console.error('âŒ Deepgram WebSocket ì˜¤ë¥˜:', error);
        reject(new Error('WebSocket ì—°ê²° ì‹¤íŒ¨'));
      };

      this.ws!.onclose = (event) => {
        this.isConnected = false;
        console.log('ğŸ”Œ Deepgram WebSocket ë‹«í˜:', event.code, event.reason);
      };
    });
  }

  // ìƒˆ ë°œí™” ì²˜ë¦¬ (ìµœê·¼ Nê°œ ë°œí™” ê¸°ë°˜ í™”ìë¶„ë¥˜)
  private async handleNewUtterance(text: string) {
    this.utterances.push(text);
    
    // ë¯¸ë¶„ë¥˜ ë°œí™” ê°œìˆ˜ ê³„ì‚°
    const unclassifiedCount = this.utterances.length - this.classifiedUtteranceCount;
    
    // ë¯¸ë¶„ë¥˜ ë°œí™”ë“¤ì„ pendingìœ¼ë¡œ í‘œì‹œ
    const pendingSegments: SpeakerSegment[] = this.utterances
      .slice(this.classifiedUtteranceCount)
      .map(t => ({ speaker: 'pending' as const, text: t }));
    
    // ê¸°ì¡´ ë¶„ë¥˜ëœ ì„¸ê·¸ë¨¼íŠ¸ + ë¯¸ë¶„ë¥˜ ë°œí™”ë“¤ì„ pendingìœ¼ë¡œ
    this.onSegmentsUpdate([...this.classifiedSegments, ...pendingSegments]);
    
    console.log(`ğŸ“ ìƒˆ ë°œí™” #${this.utterances.length}: ${text.substring(0, 40)}... (ë¯¸ë¶„ë¥˜: ${unclassifiedCount}ê°œ)`);

    // íƒ€ì´ë¨¸ ì·¨ì†Œ
    if (this.classifyTimer) {
      clearTimeout(this.classifyTimer);
    }
    
    // ë¯¸ë¶„ë¥˜ ë°œí™”ê°€ 3ê°œ ì´ìƒì´ë©´ ì¦‰ì‹œ ë¶„ë¥˜ ì‹¤í–‰
    if (unclassifiedCount >= 3) {
      console.log(`âš¡ ë¯¸ë¶„ë¥˜ ${unclassifiedCount}ê°œ â†’ ì¦‰ì‹œ í™”ìë¶„ë¥˜ ì‹¤í–‰`);
      this.classifyRecentUtterances();
    } else {
      // ì•„ë‹ˆë©´ 1.5ì´ˆ ë””ë°”ìš´ìŠ¤
      this.classifyTimer = setTimeout(() => {
        this.classifyRecentUtterances();
      }, 1500);
    }
  }

  // ì „ì²´ ë°œí™” ì¬ë¶„ë¥˜ (GPT-4o) - ì´ì „ ì˜¤ë¥˜ë„ ìˆ˜ì • ê°€ëŠ¥
  private async classifyRecentUtterances() {
    const unclassifiedCount = this.utterances.length - this.classifiedUtteranceCount;
    
    // ë¶„ë¥˜í•  ê²Œ ì—†ìœ¼ë©´ ìŠ¤í‚µ
    if (unclassifiedCount === 0) {
      return;
    }
    
    // ë¶„ë¥˜ ì¤‘ì´ë©´ ìŠ¤í‚µ (ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„ë¨)
    if (this.isClassifying) {
      console.log('â¸ï¸ ë¶„ë¥˜ ì¤‘ì´ë¯€ë¡œ ëŒ€ê¸° (ë¶„ë¥˜ ì™„ë£Œ í›„ ì¬ì‹œë„ë¨)');
      return;
    }

    this.isClassifying = true;
    
    // ë¶„ë¥˜ ì‹œì‘ ì‹œì ì˜ ë°œí™” ê°œìˆ˜ ì €ì¥ (ë¶„ë¥˜ ì¤‘ ìƒˆ ë°œí™” ê°ì§€ìš©)
    const utteranceCountAtStart = this.utterances.length;

    console.log(`ğŸ¤– ì „ì²´ ${this.utterances.length}ê°œ ë°œí™” ì¬ë¶„ë¥˜ ì‹œì‘ (ë¯¸ë¶„ë¥˜: ${unclassifiedCount}ê°œ)`);
    console.log(`ğŸ“¤ [GPT ì…ë ¥ - ì „ì²´ ë°œí™”]`, this.utterances);

    try {
      // ì „ì²´ ë°œí™”ë¥¼ GPTì— ë³´ë‚´ì„œ ì „ì²´ ì¬ë¶„ë¥˜
      const allSegments = await classifyUtterancesWithGPT(this.utterances);
      
      console.log(`ğŸ“¥ [GPT ì¶œë ¥] ${allSegments.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸:`);
      allSegments.forEach((seg, i) => {
        console.log(`   ${i+1}. [${seg.speaker}] "${seg.text}"`);
      });
      
      if (allSegments.length > 0) {
        // ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ êµì²´ (ì´ì „ ì˜¤ë¥˜ë„ ìˆ˜ì •ë¨)
        this.classifiedSegments = allSegments;
        this.classifiedUtteranceCount = utteranceCountAtStart;
        this.onSegmentsUpdate([...this.classifiedSegments]);
        console.log(`âœ… ì „ì²´ ì¬ë¶„ë¥˜ ì™„ë£Œ: ${this.classifiedSegments.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸`);
      }
    } catch (error) {
      console.error('âŒ í™”ìë¶„ë¥˜ ì˜¤ë¥˜:', error);
    } finally {
      this.isClassifying = false;
      
      // ë¶„ë¥˜ ì™„ë£Œ í›„ ìƒˆë¡œ ë“¤ì–´ì˜¨ ë°œí™”ê°€ ìˆìœ¼ë©´ ë‹¤ì‹œ ì‹œë„
      const newUtterancesDuringClassify = this.utterances.length - utteranceCountAtStart;
      if (newUtterancesDuringClassify > 0) {
        console.log(`ğŸ”„ ë¶„ë¥˜ ì¤‘ ìƒˆ ë°œí™” ${newUtterancesDuringClassify}ê°œ ì¶”ê°€ë¨ â†’ 1ì´ˆ í›„ ì¬ë¶„ë¥˜`);
        setTimeout(() => {
          this.classifyRecentUtterances();
        }, 1000);
      }
    }
  }

  // ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡
  sendAudio(audioData: ArrayBuffer): void {
    if (this.isConnected && this.ws && this.ws.readyState === WebSocket.OPEN) {
      this.ws.send(audioData);
    }
  }

  // MediaRecorder ì²­í¬ë¥¼ Deepgramì— ì „ì†¡
  async addChunk(chunk: Blob): Promise<void> {
    if (!this.isConnected || !this.ws || this.ws.readyState !== WebSocket.OPEN) {
      return;
    }

    try {
      const arrayBuffer = await chunk.arrayBuffer();
      this.ws.send(arrayBuffer);
    } catch (error) {
      // ì¡°ìš©íˆ ì‹¤íŒ¨
    }
  }

  // í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ ë°˜í™˜
  getRealtimeSegments(): SpeakerSegment[] {
    return this.classifiedSegments;
  }

  // ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
  getFullText(): string {
    return this.utterances.join(' ').trim();
  }

  // ë…¹ìŒ ì¢…ë£Œ ë° GPT-4o ìµœì¢… í™”ì ë¶„ë¥˜
  async flush(): Promise<SpeakerSegment[]> {
    console.log('ğŸ”š flush() í˜¸ì¶œ - ë…¹ìŒ ì¢…ë£Œ');
    
    // íƒ€ì´ë¨¸ ì·¨ì†Œ
    if (this.classifyTimer) {
      clearTimeout(this.classifyTimer);
      this.classifyTimer = null;
    }

    // WebSocket ë‹«ê¸°
    if (this.ws) {
      if (this.ws.readyState === WebSocket.OPEN) {
        this.ws.send(JSON.stringify({ type: 'CloseStream' }));
      }
      await new Promise(resolve => setTimeout(resolve, 500));
      this.ws.close();
      this.ws = null;
    }

    console.log(`ğŸ“ ìµœì¢… ë°œí™” ìˆ˜: ${this.utterances.length}ê°œ`);

    if (this.utterances.length === 0) {
      console.log('âš ï¸ ì „ì‚¬ëœ ë°œí™” ì—†ìŒ');
      return [];
    }

    // GPT-4oë¡œ ì „ì²´ ë°œí™” í™”ì ë¶„ë¥˜
    const segments = await classifyUtterancesWithGPT(this.utterances);
    
    this.classifiedSegments = segments;
    this.onFullUpdate(segments);
    
    return segments;
  }

  // ì—°ê²° ìƒíƒœ í™•ì¸
  isActive(): boolean {
    return this.isConnected;
  }

  // ì´ˆê¸°í™”
  reset(): void {
    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }
    if (this.classifyTimer) {
      clearTimeout(this.classifyTimer);
      this.classifyTimer = null;
    }
    this.utterances = [];
    this.classifiedSegments = [];
    this.classifiedUtteranceCount = 0;
    this.isClassifying = false;
    this.isConnected = false;
    console.log('ğŸ”„ DeepgramRealtimeTranscriber ë¦¬ì…‹');
  }
}

// React Hook for Deepgram
import { useState, useRef, useCallback } from 'react';

interface UseDeepgramOptions {
  onTranscript: (text: string, isFinal: boolean) => void;
  onSegmentsUpdate: (segments: SpeakerSegment[]) => void;
  onFullUpdate: (transcript: string, segments: SpeakerSegment[]) => void;
}

interface DisconnectResult {
  transcript: string;
  segments: SpeakerSegment[];
}

export function useDeepgram(options: UseDeepgramOptions) {
  const [isConnecting, setIsConnecting] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const transcriberRef = useRef<DeepgramRealtimeTranscriber | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const optionsRef = useRef(options);
  
  // Keep options ref updated
  optionsRef.current = options;

  const connect = useCallback(async (stream: MediaStream) => {
    setIsConnecting(true);
    setError(null);

    try {
      // Create transcriber
      transcriberRef.current = new DeepgramRealtimeTranscriber(
        (segment) => {
          optionsRef.current.onTranscript(segment.text, true);
        },
        (segments) => {
          const transcript = segments.map(s => s.text).join(' ');
          optionsRef.current.onFullUpdate(transcript, segments);
        }
      );

      // Set segments update callback
      transcriberRef.current.setOnSegmentsUpdate((segments) => {
        optionsRef.current.onSegmentsUpdate(segments);
      });

      // Connect to Deepgram
      await transcriberRef.current.connect();

      // Setup MediaRecorder to send audio chunks
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });

      mediaRecorder.ondataavailable = async (event) => {
        if (event.data.size > 0 && transcriberRef.current) {
          await transcriberRef.current.addChunk(event.data);
        }
      };

      mediaRecorder.start(100); // Send chunks every 100ms
      mediaRecorderRef.current = mediaRecorder;

      setIsConnecting(false);
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'ì—°ê²° ì‹¤íŒ¨';
      setError(errorMessage);
      setIsConnecting(false);
      throw err;
    }
  }, []);

  const disconnect = useCallback(async (): Promise<DisconnectResult> => {
    // Stop MediaRecorder
    if (mediaRecorderRef.current) {
      try {
        mediaRecorderRef.current.stop();
      } catch (e) {
        // Ignore stop errors
      }
      mediaRecorderRef.current = null;
    }

    // Flush and close transcriber
    if (transcriberRef.current) {
      try {
        const segments = await transcriberRef.current.flush();
        const transcript = transcriberRef.current.getFullText();
        transcriberRef.current = null;
        return { transcript, segments };
      } catch (e) {
        console.error('Disconnect error:', e);
        transcriberRef.current = null;
      }
    }
    
    return { transcript: '', segments: [] };
  }, []);

  return {
    connect,
    disconnect,
    isConnecting,
    error
  };
}

export default {
  DeepgramRealtimeTranscriber,
  useDeepgram,
};
